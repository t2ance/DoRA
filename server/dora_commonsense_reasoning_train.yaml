apiVersion: batch/v1
kind: Job
metadata:
  name: dora-commonsense-reasoning-train
spec:
  template:
    spec:
      containers:
        - name: gpu-container
          image: continuumio/anaconda3
          command: [ "/bin/bash","-c" ]
          args: [
            "nvidia-smi;
             git clone https://github.com/t2ance/DoRA.git;
             cd DoRA;
             cd commonsense_reasoning;
             conda create -n dora_llama python=3.10;
             echo 'created!';
             conda init bash;
             source /opt/conda/etc/profile.d/conda.sh;
             conda activate dora_llama;
             echo 'activated!';
             pip install -r requirements.txt;
             echo 'installed!';
             bash ./download_data.sh;
             echo 'downloaded!';
             sh llama_7B_Dora.sh 32 64 /data/dora/finetuned_result/dora_r32 0;
             "
          ]
          #             jupyter lab --ip=0.0.0.0 --port=8888 --NotebookApp.token=627a7b3b --no-browser --allow-root;
          volumeMounts:
            - mountPath: /data
              name: peijia-volume3
          resources:
            requests:
              #          nvidia.com/gpu: "1"
              #          nvidia.com/rtxa6000: "1"
              nvidia.com/a100: "1"
              memory: "12G"
              cpu: "2"
            limits:
              #          nvidia.com/gpu: "1"
              #          nvidia.com/rtxa6000: "1"
              nvidia.com/a100: "1"
              memory: "12G"
              cpu: "2"
      #  affinity:
      #    nodeAffinity:
      #      requiredDuringSchedulingIgnoredDuringExecution:
      #        nodeSelectorTerms:
      #          - matchExpressions:
      #              - key: nvidia.com/gpu.product
      #                operator: In
      #                values:
      #                  - NVIDIA-GeForce-RTX-3090
      volumes:
        - name: peijia-volume3
          persistentVolumeClaim:
            claimName: peijia-volume3
      restartPolicy: Never
